{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files(path):\n",
    "    file_contents = dict()\n",
    "\n",
    "    for filename in os.listdir(path):\n",
    "        if filename.endswith('.txt'):\n",
    "            with open(os.path.join(path, filename), 'r') as f:\n",
    "                content = f.read()\n",
    "                file_contents[filename] = content\n",
    "\n",
    "    print(\"... Reading files in path : \", path)\n",
    "    print(\"Number of files read: \", len(file_contents))\n",
    "\n",
    "    return file_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Reading files in path :  data/effectiveness/train\n",
      "Number of files read:  4191\n",
      "... Reading files in path :  data/label/train\n",
      "Number of files read:  15594\n"
     ]
    }
   ],
   "source": [
    "effectiveness_contents = read_files('data/effectiveness/train') # 4191\n",
    "label_contents = read_files('data/label/train') # 15594"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 36765 entries, 0 to 36764\n",
      "Data columns (total 5 columns):\n",
      " #   Column                   Non-Null Count  Dtype \n",
      "---  ------                   --------------  ----- \n",
      " 0   discourse_id             36765 non-null  object\n",
      " 1   essay_id                 36765 non-null  object\n",
      " 2   discourse_text           36765 non-null  object\n",
      " 3   discourse_type           36765 non-null  object\n",
      " 4   discourse_effectiveness  36765 non-null  object\n",
      "dtypes: object(5)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('data/effectiveness/train.csv')\n",
    "train.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>discourse_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Limiting the usage of cars has personal and pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>With so many things in this world that few peo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>It is no secret that morning traffic jams and ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_0                                     discourse_text\n",
       "0        0  Limiting the usage of cars has personal and pr...\n",
       "1        1  With so many things in this world that few peo...\n",
       "2        2  It is no secret that morning traffic jams and ..."
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = (train[train['discourse_effectiveness'] == 'Effective']\n",
    "         .reset_index()\n",
    "         .reset_index()[['level_0', 'discourse_text']]\n",
    "         .replace(r'\\n',' ', regex=True) \n",
    "        )\n",
    "train['discourse_text'].str.strip()\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>essay_id</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>739a6d00f44a</td>\n",
       "      <td>D72CB1C11673</td>\n",
       "      <td>Taking other peoples advice and doing what the...</td>\n",
       "      <td>Evidence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bcfae2c9a244</td>\n",
       "      <td>D72CB1C11673</td>\n",
       "      <td>You can learn from others experiences by seeki...</td>\n",
       "      <td>Concluding Statement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93578d946723</td>\n",
       "      <td>D72CB1C11673</td>\n",
       "      <td>can be very helpful and beneficial.</td>\n",
       "      <td>Claim</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   discourse_id      essay_id  \\\n",
       "8  739a6d00f44a  D72CB1C11673   \n",
       "9  bcfae2c9a244  D72CB1C11673   \n",
       "4  93578d946723  D72CB1C11673   \n",
       "\n",
       "                                      discourse_text        discourse_type  \n",
       "8  Taking other peoples advice and doing what the...              Evidence  \n",
       "9  You can learn from others experiences by seeki...  Concluding Statement  \n",
       "4               can be very helpful and beneficial.                  Claim  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('data/effectiveness/test.csv')\n",
    "test.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>discourse_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Making choices in life can be very difficult. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Seeking multiple opinions can help a person ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>it can decrease stress levels</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                     discourse_text\n",
       "0      0  Making choices in life can be very difficult. ...\n",
       "1      1  Seeking multiple opinions can help a person ma...\n",
       "2      2                     it can decrease stress levels "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = test.reset_index()[['index', 'discourse_text']].replace(r'\\n',' ', regex=True) \n",
    "test['discourse_text'].str.strip()\n",
    "test.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Retrieval Augmented Generation\n",
    "> * Learn to retrieve a sequence from an existing corpus of human-written prototypes (e.g., dialogue responses)\n",
    "> * Learn to edit the retrieved sequence by adding, removing, and modifying tokens in the prototype – this will still result in a more “human-like” generation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastRAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "`ColBERT` (dense retriever) \n",
    "1. use NN to encode all documents into representative vectors\n",
    "2. encodes query into a vector and using vector similarity search\n",
    "\n",
    "`PLAID` engine\n",
    "* use aset of filtering steps to improve latency times for ColBERT-based indexes\n",
    "\n",
    "\n",
    "    `PLAIDDocumentStore` document store class\n",
    "    * `collection_path` is the path to the documents collection, in the form of a TSV file with columns being \"id,content,title\" where the title is optional.\n",
    "    * `checkpoint_path` is the path for the encoder model, needed to encode queries into vectors at run time. Could be a local path to a model or a model hosted on HuggingFace hub. In order to use our trained model based on NaturalQuestions, provide the path Intel/ColBERT-NQ; see Model Hub for more details.\n",
    "    * `index_path` location of the indexed documents. The index contains the optimized and compressed vector representation of all the documents. Index can be created by the user given a collection and a checkpoint, or can be specified via a path.\n",
    "\n",
    "`Fusion-in-Decoder` (`FiD`)\n",
    "* transformer-based generative model (based on T5 architecture)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colbert.infra import Run, RunConfig, ColBERTConfig\n",
    "from colbert.data import Queries, Collection\n",
    "from colbert import Indexer, Searcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>Limiting the usage of cars has personal and professional support all across the globe and yet it has yet to be embraced everywhere. Statistical proof show where it may help and real life examples of some of the effects of reducing, or getting rid of altogether, cars in one's daily life. While \"recent studies suggest that Americans are buying fewer cars, driving less and getting fewer licenses as each year goes by\" (Source 4), is that really enough or for the right reason? There are plenty of reasons to stop, or limit, the amount of cars being driven on the roads for every kind of person, from the hippie to the businessman, from the mom to the college student.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>With so many things in this world that few peo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>It is no secret that morning traffic jams and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>the environment suffers greatly from the many ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  \\\n",
       "0  1   \n",
       "1  2   \n",
       "2  3   \n",
       "\n",
       "  Limiting the usage of cars has personal and professional support all across the globe and yet it has yet to be embraced everywhere. Statistical proof show where it may help and real life examples of some of the effects of reducing, or getting rid of altogether, cars in one's daily life. While \"recent studies suggest that Americans are buying fewer cars, driving less and getting fewer licenses as each year goes by\" (Source 4), is that really enough or for the right reason? There are plenty of reasons to stop, or limit, the amount of cars being driven on the roads for every kind of person, from the hippie to the businessman, from the mom to the college student.   \n",
       "0  With so many things in this world that few peo...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
       "1  It is no secret that morning traffic jams and ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
       "2  the environment suffers greatly from the many ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataroot = 'data'\n",
    "dataset = 'effective'\n",
    "datasplit = 'train'\n",
    "\n",
    "queries = os.path.join(dataroot, dataset, datasplit, 'questions.search.tsv')\n",
    "collection = os.path.join(dataroot, dataset, datasplit, 'collection.tsv')\n",
    "\n",
    "with open(collection, 'w') as write_tsv:\n",
    "   write_tsv.write(train.to_csv(sep='\\t', index=False, header=False))\n",
    "\n",
    "with open(queries, 'w') as write_tsv:\n",
    "   write_tsv.write(test.to_csv(sep='\\t', index=False, header=False))\n",
    "\n",
    "tsv_read = pd.read_csv(collection, sep='\\t')\n",
    "tsv_read.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mar 01, 18:56:44] #> Loading the queries from data/effective/train/questions.search.tsv ...\n",
      "[Mar 01, 18:56:44] #> Got 10 queries. All QIDs are unique.\n",
      "\n",
      "[Mar 01, 18:56:44] #> Loading collection...\n",
      "0M \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Loaded 10 queries and 9,326 passages'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = Queries(path=queries)\n",
    "collection = Collection(path=collection)\n",
    "\n",
    "f'Loaded {len(queries)} queries and {len(collection):,} passages'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[Mar 01, 18:56:47] #> Note: Output directory /Users/az/Documents/Stanford/Classes/CS224N/final/argue-better/experiments/notebook/indexes/effective.train.2bits already exists\n",
      "\n",
      "\n",
      "#> Starting...\n",
      "#> Starting...\n",
      "WARNING: faiss must be imported for indexing\n",
      "{\n",
      "    \"query_token_id\": \"[unused0]\",\n",
      "    \"doc_token_id\": \"[unused1]\",\n",
      "    \"query_token\": \"[Q]\",\n",
      "    \"doc_token\": \"[D]\",\n",
      "    \"ncells\": null,\n",
      "    \"centroid_score_threshold\": null,\n",
      "    \"ndocs\": null,\n",
      "    \"index_path\": null,\n",
      "    \"nbits\": 2,\n",
      "    \"kmeans_niters\": 20,\n",
      "    \"resume\": false,\n",
      "    \"similarity\": \"cosine\",\n",
      "    \"bsize\": 64,\n",
      "    \"accumsteps\": 1,\n",
      "    \"lr\": 1e-5,\n",
      "    \"maxsteps\": 400000,\n",
      "    \"save_every\": null,\n",
      "    \"warmup\": 20000,\n",
      "    \"warmup_bert\": null,\n",
      "    \"relu\": false,\n",
      "    \"nway\": 64,\n",
      "    \"use_ib_negatives\": true,\n",
      "    \"reranker\": false,\n",
      "    \"distillation_alpha\": 1.0,\n",
      "    \"ignore_scores\": false,\n",
      "    \"model_name\": \"bert-base-uncased\",\n",
      "    \"query_maxlen\": 32,\n",
      "    \"attend_to_mask_tokens\": false,\n",
      "    \"interaction\": \"colbert\",\n",
      "    \"dim\": 128,\n",
      "    \"doc_maxlen\": 180,\n",
      "    \"mask_punctuation\": true,\n",
      "    \"checkpoint\": \"downloads\\/colbertv2.0\",\n",
      "    \"triples\": \"\\/future\\/u\\/okhattab\\/root\\/unit\\/experiments\\/2021.10\\/downstream.distillation.round2.2_score\\/round2.nway6.cosine.ib\\/examples.64.json\",\n",
      "    \"collection\": {\n",
      "        \"provenance\": \"data\\/effective\\/train\\/collection.tsv\"\n",
      "    },\n",
      "    \"queries\": \"\\/future\\/u\\/okhattab\\/data\\/MSMARCO\\/queries.train.tsv\",\n",
      "    \"index_name\": \"effective.train.2bits\",\n",
      "    \"overwrite\": false,\n",
      "    \"root\": \"\\/Users\\/az\\/Documents\\/Stanford\\/Classes\\/CS224N\\/final\\/argue-better\\/experiments\",\n",
      "    \"experiment\": \"notebook\",\n",
      "    \"index_root\": null,\n",
      "    \"name\": \"2023-03\\/01\\/18.15.18\",\n",
      "    \"rank\": 0,\n",
      "    \"nranks\": 5,\n",
      "    \"amp\": true,\n",
      "    \"gpus\": 0\n",
      "}\n",
      "[Mar 01, 18:56:51] Loading segmented_maxsim_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:118: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/torch/amp/autocast_mode.py:202: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mar 01, 18:56:51] [0] \t\t # of sampled PIDs = 9326 \t sampled_pids[:3] = [6825, 166, 4892]\n",
      "[Mar 01, 18:56:51] [0] \t\t #> Encoding 1866 passages..\n",
      "#> Starting...\n",
      "WARNING: faiss must be imported for indexing\n",
      "[Mar 01, 18:56:54] Loading segmented_maxsim_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:118: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mar 01, 18:56:54] [1] \t\t #> Encoding 1866 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/torch/amp/autocast_mode.py:202: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#> Starting...\n",
      "WARNING: faiss must be imported for indexing\n",
      "[Mar 01, 18:56:59] Loading segmented_maxsim_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:118: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mar 01, 18:57:00] [2] \t\t #> Encoding 1866 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/torch/amp/autocast_mode.py:202: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#> Starting...\n",
      "WARNING: faiss must be imported for indexing\n",
      "[Mar 01, 18:57:05] Loading segmented_maxsim_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:118: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mar 01, 18:57:05] [3] \t\t #> Encoding 1866 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/torch/amp/autocast_mode.py:202: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: faiss must be imported for indexing\n",
      "[Mar 01, 18:57:13] Loading segmented_maxsim_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:118: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mar 01, 18:57:13] [4] \t\t #> Encoding 1862 passages..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/torch/amp/autocast_mode.py:202: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
      "100%|██████████| 30/30 [20:00<00:00, 40.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mar 01, 19:16:52] [0] \t\t avg_doclen_est = 68.29689025878906 \t len(local_sample) = 1,866\n",
      "[Mar 01, 19:16:52] [0] \t\t Creaing 8,192 partitions.\n",
      "[Mar 01, 19:16:52] [0] \t\t *Estimated* 636,936 embeddings.\n",
      "[Mar 01, 19:16:52] [0] \t\t #> Saving the indexing plan to /Users/az/Documents/Stanford/Classes/CS224N/final/argue-better/experiments/notebook/indexes/effective.train.2bits/plan.json ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-8:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/colbert/infra/launcher.py\", line 117, in setup_new_process\n",
      "    return_val = callee(config, *args)\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/colbert/indexing/collection_indexer.py\", line 31, in encode\n",
      "    encoder.run(shared_lists)\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/colbert/indexing/collection_indexer.py\", line 57, in run\n",
      "    distributed.barrier(self.rank)\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/colbert/utils/distributed.py\", line 38, in barrier\n",
      "    torch.distributed.barrier(device_ids=[rank % torch.cuda.device_count()])\n",
      "ZeroDivisionError: integer division or modulo by zero\n",
      "100%|██████████| 30/30 [19:59<00:00, 39.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mar 01, 19:16:55] [1] \t\t avg_doclen_est = 67.5959243774414 \t len(local_sample) = 1,866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-9:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/colbert/infra/launcher.py\", line 117, in setup_new_process\n",
      "    return_val = callee(config, *args)\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/colbert/indexing/collection_indexer.py\", line 31, in encode\n",
      "    encoder.run(shared_lists)\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/colbert/indexing/collection_indexer.py\", line 57, in run\n",
      "    distributed.barrier(self.rank)\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/colbert/utils/distributed.py\", line 38, in barrier\n",
      "    torch.distributed.barrier(device_ids=[rank % torch.cuda.device_count()])\n",
      "ZeroDivisionError: integer division or modulo by zero\n",
      "100%|██████████| 30/30 [20:07<00:00, 40.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mar 01, 19:17:08] [2] \t\t avg_doclen_est = 59.00053405761719 \t len(local_sample) = 1,866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-10:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/colbert/infra/launcher.py\", line 117, in setup_new_process\n",
      "    return_val = callee(config, *args)\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/colbert/indexing/collection_indexer.py\", line 31, in encode\n",
      "    encoder.run(shared_lists)\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/colbert/indexing/collection_indexer.py\", line 57, in run\n",
      "    distributed.barrier(self.rank)\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/colbert/utils/distributed.py\", line 38, in barrier\n",
      "    torch.distributed.barrier(device_ids=[rank % torch.cuda.device_count()])\n",
      "ZeroDivisionError: integer division or modulo by zero\n",
      "100%|██████████| 30/30 [20:03<00:00, 40.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mar 01, 19:17:10] [3] \t\t avg_doclen_est = 59.81671905517578 \t len(local_sample) = 1,866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-11:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/colbert/infra/launcher.py\", line 117, in setup_new_process\n",
      "    return_val = callee(config, *args)\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/colbert/indexing/collection_indexer.py\", line 31, in encode\n",
      "    encoder.run(shared_lists)\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/colbert/indexing/collection_indexer.py\", line 57, in run\n",
      "    distributed.barrier(self.rank)\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/colbert/utils/distributed.py\", line 38, in barrier\n",
      "    torch.distributed.barrier(device_ids=[rank % torch.cuda.device_count()])\n",
      "ZeroDivisionError: integer division or modulo by zero\n",
      "100%|██████████| 30/30 [19:56<00:00, 39.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mar 01, 19:17:11] [4] \t\t avg_doclen_est = 70.16970825195312 \t len(local_sample) = 1,862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-12:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/colbert/infra/launcher.py\", line 117, in setup_new_process\n",
      "    return_val = callee(config, *args)\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/colbert/indexing/collection_indexer.py\", line 31, in encode\n",
      "    encoder.run(shared_lists)\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/colbert/indexing/collection_indexer.py\", line 57, in run\n",
      "    distributed.barrier(self.rank)\n",
      "  File \"/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/colbert/utils/distributed.py\", line 38, in barrier\n",
      "    torch.distributed.barrier(device_ids=[rank % torch.cuda.device_count()])\n",
      "ZeroDivisionError: integer division or modulo by zero\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m config \u001b[38;5;241m=\u001b[39m ColBERTConfig(\n\u001b[1;32m      7\u001b[0m     nbits\u001b[38;5;241m=\u001b[39mnbits,\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m      9\u001b[0m indexer \u001b[38;5;241m=\u001b[39m Indexer(checkpoint\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdownloads/colbertv2.0\u001b[39m\u001b[38;5;124m'\u001b[39m, config\u001b[38;5;241m=\u001b[39mconfig)\n\u001b[0;32m---> 10\u001b[0m \u001b[43mindexer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/colbert/indexer.py:77\u001b[0m, in \u001b[0;36mIndexer.index\u001b[0;34m(self, name, collection, overwrite)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merase()\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index_does_not_exist \u001b[38;5;129;01mor\u001b[39;00m overwrite \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreuse\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 77\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcollection\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_path\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/colbert/indexer.py:87\u001b[0m, in \u001b[0;36mIndexer.__launch\u001b[0;34m(self, collection)\u001b[0m\n\u001b[1;32m     84\u001b[0m shared_queues \u001b[38;5;241m=\u001b[39m [manager\u001b[38;5;241m.\u001b[39mQueue(maxsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnranks)]\n\u001b[1;32m     86\u001b[0m launcher \u001b[38;5;241m=\u001b[39m Launcher(encode)\n\u001b[0;32m---> 87\u001b[0m \u001b[43mlauncher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlaunch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshared_lists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshared_queues\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/colbert/infra/launcher.py:78\u001b[0m, in \u001b[0;36mLauncher.launch\u001b[0;34m(self, custom_config, *args)\u001b[0m\n\u001b[1;32m     74\u001b[0m print_memory_stats(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMAIN\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# TODO: If the processes crash upon join, raise an exception and don't block on .get() below!\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m return_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m([return_value_queue\u001b[38;5;241m.\u001b[39mget() \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m all_procs])\n\u001b[1;32m     79\u001b[0m return_values \u001b[38;5;241m=\u001b[39m [val \u001b[38;5;28;01mfor\u001b[39;00m rank, val \u001b[38;5;129;01min\u001b[39;00m return_values]\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_all:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/colbert/infra/launcher.py:78\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     74\u001b[0m print_memory_stats(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMAIN\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# TODO: If the processes crash upon join, raise an exception and don't block on .get() below!\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m return_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m([\u001b[43mreturn_value_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m all_procs])\n\u001b[1;32m     79\u001b[0m return_values \u001b[38;5;241m=\u001b[39m [val \u001b[38;5;28;01mfor\u001b[39;00m rank, val \u001b[38;5;129;01min\u001b[39;00m return_values]\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_all:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cs224n/lib/python3.10/multiprocessing/queues.py:103\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block \u001b[38;5;129;01mand\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rlock:\n\u001b[0;32m--> 103\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sem\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cs224n/lib/python3.10/multiprocessing/connection.py:221\u001b[0m, in \u001b[0;36m_ConnectionBase.recv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m maxlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m maxlength \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnegative maxlength\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 221\u001b[0m buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaxlength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m buf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bad_message_length()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cs224n/lib/python3.10/multiprocessing/connection.py:419\u001b[0m, in \u001b[0;36mConnection._recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_recv_bytes\u001b[39m(\u001b[38;5;28mself\u001b[39m, maxsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 419\u001b[0m     buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    420\u001b[0m     size, \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39munpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m!i\u001b[39m\u001b[38;5;124m\"\u001b[39m, buf\u001b[38;5;241m.\u001b[39mgetvalue())\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cs224n/lib/python3.10/multiprocessing/connection.py:384\u001b[0m, in \u001b[0;36mConnection._recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    382\u001b[0m remaining \u001b[38;5;241m=\u001b[39m size\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m remaining \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 384\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m \u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    385\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunk)\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nbits = 2\n",
    "index_name = f'{dataset}.{datasplit}.{nbits}bits'\n",
    "\n",
    "with Run().context(RunConfig(nranks=5, experiment='notebook')):\n",
    "\n",
    "    config = ColBERTConfig(\n",
    "        nbits=nbits,\n",
    "    )\n",
    "    indexer = Indexer(checkpoint='downloads/colbertv2.0', config=config)\n",
    "    print('start indexing\")\n",
    "    indexer.index(name=index_name, collection=collection, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/az/Documents/Stanford/Classes/CS224N/final/argue-better/experiments/notebook/indexes/effective.train.2bits'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexer.get_index() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Mar 01, 19:27:29] Loading segmented_maxsim_cpp extension (set COLBERT_LOAD_TORCH_EXTENSION_VERBOSE=True for more info)...\n",
      "[Mar 01, 19:27:29] #> Loading codec...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/az/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:118: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/az/Documents/Stanford/Classes/CS224N/final/argue-better/experiments/notebook/indexes/effective.train.2bits/centroids.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[76], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Run()\u001b[38;5;241m.\u001b[39mcontext(RunConfig(experiment\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnotebook\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[0;32m----> 2\u001b[0m     searcher \u001b[38;5;241m=\u001b[39m \u001b[43mSearcher\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/colbert/searcher.py:41\u001b[0m, in \u001b[0;36mSearcher.__init__\u001b[0;34m(self, index, checkpoint, collection, config)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_gpu:\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpoint \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[0;32m---> 41\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mranker \u001b[38;5;241m=\u001b[39m \u001b[43mIndexScorer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_gpu\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m print_memory_stats()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/colbert/search/index_storage.py:19\u001b[0m, in \u001b[0;36mIndexScorer.__init__\u001b[0;34m(self, index_path, use_gpu)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index_path, use_gpu\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mindex_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_gpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_gpu\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     IndexScorer\u001b[38;5;241m.\u001b[39mtry_load_torch_extensions(use_gpu)\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings_strided \u001b[38;5;241m=\u001b[39m ResidualEmbeddingsStrided(\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcodec, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdoclens\n\u001b[1;32m     25\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/colbert/search/index_loader.py:18\u001b[0m, in \u001b[0;36mIndexLoader.__init__\u001b[0;34m(self, index_path, use_gpu)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_path \u001b[38;5;241m=\u001b[39m index_path\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_gpu \u001b[38;5;241m=\u001b[39m use_gpu\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_codec\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_ivf()\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_doclens()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/colbert/search/index_loader.py:26\u001b[0m, in \u001b[0;36mIndexLoader._load_codec\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load_codec\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     25\u001b[0m     print_message(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#> Loading codec...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcodec \u001b[38;5;241m=\u001b[39m \u001b[43mResidualCodec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/colbert/indexing/codecs/residual.py:132\u001b[0m, in \u001b[0;36mResidualCodec.load\u001b[0;34m(cls, index_path)\u001b[0m\n\u001b[1;32m    129\u001b[0m avgresidual_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(index_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mavg_residual.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    130\u001b[0m buckets_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(index_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuckets.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 132\u001b[0m centroids \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcentroids_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m avg_residual \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(avgresidual_path, map_location\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    134\u001b[0m bucket_cutoffs, bucket_weights \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(buckets_path, map_location\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/torch/serialization.py:771\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    769\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 771\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    773\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    774\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    775\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    776\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/torch/serialization.py:270\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 270\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    272\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/torch/serialization.py:251\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 251\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_open_file, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/az/Documents/Stanford/Classes/CS224N/final/argue-better/experiments/notebook/indexes/effective.train.2bits/centroids.pt'"
     ]
    }
   ],
   "source": [
    "with Run().context(RunConfig(experiment='notebook')):\n",
    "    searcher = Searcher(index=index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: faiss must be imported for indexing\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "PLAIDDocumentStore.__init__() missing 1 required positional argument: 'index_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfastrag\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# https://github.com/IntelLabs/fastRAG/blob/main/models.md\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m store \u001b[38;5;241m=\u001b[39m \u001b[43mPLAIDDocumentStore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mIntel/ColBERT-NQ\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mcollection_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/train.tsv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/cs224n/lib/python3.10/site-packages/haystack/nodes/base.py:48\u001b[0m, in \u001b[0;36mexportable_to_yaml.<locals>.wrapper_exportable_to_yaml\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_component_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m\"\u001b[39m][k] \u001b[38;5;241m=\u001b[39m v\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Call the actuall __init__ function with all the arguments\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m \u001b[43minit_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: PLAIDDocumentStore.__init__() missing 1 required positional argument: 'index_path'"
     ]
    }
   ],
   "source": [
    "from fastrag.stores import PLAIDDocumentStore\n",
    "import fastrag, torch\n",
    "\n",
    "# https://github.com/IntelLabs/fastRAG/blob/main/models.md\n",
    "\n",
    "store = PLAIDDocumentStore(index_path=\"\",\n",
    "                           checkpoint_path=\"downloads/,\n",
    "                           collection_path=collection)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastrag.retrievers.colbert import ColBERTRetriever\n",
    "retriever = ColBERTRetriever(store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the answer\n",
    "res['answers'][0].answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "ac62b4d06facacce709a0ffb09328fa4cc9c954f12b15e7d457565310d842b4d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
